{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis on Movie Reviews using Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing all the neccessary libraries\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets, neighbors\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import cross_validate\n",
    "#from sklearn import cross_validation\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "import scikitplot.metrics as sciplot\n",
    "from sklearn.metrics import accuracy_score\n",
    "import sklearn.metrics as metrics\n",
    "import math\n",
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Data Source: <b> https://www.kaggle.com/c/sentiment-analysis-on-movie-reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attribute Information: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Phrase Id\n",
    "2. Sentiment Id\n",
    "3. Phrase\n",
    "4. Sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Objective: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our main objective for this analysis is to train a model which can seperate the postive and negative reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### While pre-processing the original dataset we have taken into consideration the following points. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. We will classify a review to be positive if and only if the corresponding Score for the given review is 3 or 4.\n",
    "2. We will classify a review to be negative if and only if the corresponding Score for the given review is 0 or 1.\n",
    "3. We will ignore the reviews for the time being which has a Score rating of 2. Because 2 can be thought of as a neutral review. It's neither negative nor positive.\n",
    "4. We will remove the duplicate entries from the dataset.\n",
    "5. We will train our final model using four featurizations -> bag of words model, tf-idf model, average word-to-vec model and tf-idf weighted word-to-vec model.\n",
    "6. So at end of the training the model will be trained on the above four featurizations to determine if a given review is positive or negative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Raw Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data.tsv.zip'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata.tsv.zip\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelimiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;130;43;01m\\t\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# data= data[1:1000]\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m\"\u001b[39m,np\u001b[38;5;241m.\u001b[39mshape(data))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m    947\u001b[0m )\n\u001b[0;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1733\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1734\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1736\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1737\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1738\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1739\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1740\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1741\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1742\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1743\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1744\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:779\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    774\u001b[0m \u001b[38;5;66;03m# ZIP Compression\u001b[39;00m\n\u001b[0;32m    775\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m compression \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzip\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    776\u001b[0m     \u001b[38;5;66;03m# error: Argument 1 to \"_BytesZipFile\" has incompatible type\u001b[39;00m\n\u001b[0;32m    777\u001b[0m     \u001b[38;5;66;03m# \"Union[str, BaseBuffer]\"; expected \"Union[Union[str, PathLike[str]],\u001b[39;00m\n\u001b[0;32m    778\u001b[0m     \u001b[38;5;66;03m# ReadBuffer[bytes], WriteBuffer[bytes]]\"\u001b[39;00m\n\u001b[1;32m--> 779\u001b[0m     handle \u001b[38;5;241m=\u001b[39m \u001b[43m_BytesZipFile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    780\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcompression_args\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m    781\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    782\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m handle\u001b[38;5;241m.\u001b[39mbuffer\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    783\u001b[0m         handles\u001b[38;5;241m.\u001b[39mappend(handle)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:1022\u001b[0m, in \u001b[0;36m_BytesZipFile.__init__\u001b[1;34m(self, file, mode, archive_name, **kwargs)\u001b[0m\n\u001b[0;32m   1018\u001b[0m kwargs\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, zipfile\u001b[38;5;241m.\u001b[39mZIP_DEFLATED)\n\u001b[0;32m   1019\u001b[0m \u001b[38;5;66;03m# error: Argument 1 to \"ZipFile\" has incompatible type \"Union[\u001b[39;00m\n\u001b[0;32m   1020\u001b[0m \u001b[38;5;66;03m# Union[str, PathLike[str]], ReadBuffer[bytes], WriteBuffer[bytes]]\";\u001b[39;00m\n\u001b[0;32m   1021\u001b[0m \u001b[38;5;66;03m# expected \"Union[Union[str, PathLike[str]], IO[bytes]]\"\u001b[39;00m\n\u001b[1;32m-> 1022\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuffer \u001b[38;5;241m=\u001b[39m \u001b[43mzipfile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mZipFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\zipfile.py:1284\u001b[0m, in \u001b[0;36mZipFile.__init__\u001b[1;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps, metadata_encoding)\u001b[0m\n\u001b[0;32m   1282\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m   1283\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1284\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp \u001b[38;5;241m=\u001b[39m \u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilemode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1285\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[0;32m   1286\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m filemode \u001b[38;5;129;01min\u001b[39;00m modeDict:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data.tsv.zip'"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('data.tsv.zip', delimiter='\\t')\n",
    "# data= data[1:1000]\n",
    "print(\"shape\",np.shape(data))\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data=data\n",
    "final_data['SentimentPolarity'] = final_data['Sentiment'].apply(lambda x : 'Positive' if x > 2 else 'Negative')\n",
    "final_data['Class_Labels'] = final_data['SentimentPolarity'].apply(lambda x : 1 if x == 'Positive' else 0)\n",
    "final_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display distribution of Postive and Negative reviews in a bar graph\n",
    "final_data[\"Class_Labels\"].value_counts().plot(kind='bar',color=['green','red'],title='Distribution Of Positive and Negative reviews',figsize=(5,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Review "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data requires some preprocessing before we go on further with analysis and making the prediction model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence in the Preprocessing phase we do the following in the order below:-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Begin by removing the html tags\n",
    "2. Remove any punctuations or limited set of special characters like , or . or # etc.\n",
    "3. Check if the word is made up of english letters and is not alpha-numeric\n",
    "4. Check to see if the length of the word is greater than 2 (as it was researched that there is no adjective in 2-letters)\n",
    "5. Convert the word to lowercase\n",
    "6. Remove Stopwords\n",
    "7. Finally Snowball Stemming the word (it was obsereved to be better than Porter Stemming)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After which we collect the words used to describe positive and negative reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Printing some random reviews.\n",
    "sent_1 = final_data['Phrase'].values[0]\n",
    "print(sent_1)\n",
    "print(\"Review Polarity: {}\".format(final_data['SentimentPolarity'].values[0]))\n",
    "print(\"=\"*215)\n",
    "\n",
    "sent_2 = final_data['Phrase'].values[1000]\n",
    "print(sent_2)\n",
    "print(\"Review Polarity: {}\".format(final_data['SentimentPolarity'].values[1000]))\n",
    "print(\"=\"*215)\n",
    "\n",
    "sent_3 = final_data['Phrase'].values[1500]\n",
    "print(sent_3)\n",
    "print(\"Review Polarity: {}\".format(final_data['SentimentPolarity'].values[1500]))\n",
    "print(\"=\"*215)\n",
    "\n",
    "sent_4 = final_data['Phrase'].values[4900]\n",
    "print(sent_4)\n",
    "print(\"Review Polarity: {}\".format(final_data['SentimentPolarity'].values[4900]))\n",
    "print(\"=\"*215)\n",
    "\n",
    "sent_5 = final_data['Phrase'].values[12566]\n",
    "print(sent_5)\n",
    "print(\"Review Polarity: {}\".format(final_data['SentimentPolarity'].values[12566]))\n",
    "print(\"=\"*215)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove urls from text python: https://stackoverflow.com/a/40823105/4084039\n",
    "import re\n",
    "sent_1 = re.sub(r\"http\\S+\", \" \", sent_1)\n",
    "sent_2 = re.sub(r\"http\\S+\", \" \", sent_2)\n",
    "sent_3 = re.sub(r\"http\\S+\", \" \", sent_3)\n",
    "sent_4 = re.sub(r\"http\\S+\", \" \", sent_4)\n",
    "sent_5 = re.sub(r\"http\\S+\", \" \", sent_5)\n",
    "\n",
    "\n",
    "print(sent_1,\"\\n\")\n",
    "print(\"=\"*215)\n",
    "print(sent_2,\"\\n\")\n",
    "print(\"=\"*215)\n",
    "print(sent_3,\"\\n\")\n",
    "print(\"=\"*215)\n",
    "print(sent_4,\"\\n\")\n",
    "print(\"=\"*215)\n",
    "print(sent_5,\"\\n\")\n",
    "print(\"=\"*215)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to clean html tags from a sentence\n",
    "def removeHtml(sentence): \n",
    "    pattern = re.compile('<.*?>')\n",
    "    cleaned_text = re.sub(pattern,' ',sentence)\n",
    "    return cleaned_text\n",
    "\n",
    "\n",
    "print(removeHtml(sent_1) + \"\\n\")\n",
    "print(removeHtml(sent_2) + \"\\n\")\n",
    "print(removeHtml(sent_3) + \"\\n\")\n",
    "print(removeHtml(sent_4) + \"\\n\")\n",
    "print(removeHtml(sent_5) + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/a/47091490/4084039\n",
    "# https://en.wikipedia.org/wiki/Wikipedia:List_of_English_contractions\n",
    "import re\n",
    "\n",
    "#Expand the reviews x is aninput string of any length. Convert all the words to lower case\n",
    "def decontracted(x):\n",
    "    x = str(x).lower()\n",
    "    x = x.replace(\",000,000\", \" m\").replace(\",000\", \" k\").replace(\"′\", \"'\").replace(\"’\", \"'\")\\\n",
    "                           .replace(\"won't\", \" will not\").replace(\"cannot\", \" can not\").replace(\"can't\", \" can not\")\\\n",
    "                           .replace(\"n't\", \" not\").replace(\"what's\", \" what is\").replace(\"it's\", \" it is\")\\\n",
    "                           .replace(\"'ve\", \" have\").replace(\"'m\", \" am\").replace(\"'re\", \" are\")\\\n",
    "                           .replace(\"he's\", \" he is\").replace(\"she's\", \" she is\").replace(\"'s\", \" own\")\\\n",
    "                           .replace(\"%\", \" percent \").replace(\"₹\", \" rupee \").replace(\"$\", \" dollar \")\\\n",
    "                           .replace(\"€\", \" euro \").replace(\"'ll\", \" will\").replace(\"how's\",\" how has\").replace(\"y'all\",\" you all\")\\\n",
    "                           .replace(\"o'clock\",\" of the clock\").replace(\"ne'er\",\" never\").replace(\"let's\",\" let us\")\\\n",
    "                           .replace(\"finna\",\" fixing to\").replace(\"gonna\",\" going to\").replace(\"gimme\",\" give me\").replace(\"gotta\",\" got to\").replace(\"'d\",\" would\")\\\n",
    "                           .replace(\"daresn't\",\" dare not\").replace(\"dasn't\",\" dare not\").replace(\"e'er\",\" ever\").replace(\"everyone's\",\" everyone is\")\\\n",
    "                           .replace(\"'cause'\",\" because\")\n",
    "    \n",
    "    x = re.sub(r\"([0-9]+)000000\", r\"\\1m\", x)\n",
    "    x = re.sub(r\"([0-9]+)000\", r\"\\1k\", x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove words with numbers python: https://stackoverflow.com/a/18082370/4084039\n",
    "'''\n",
    ">>> import re\n",
    ">>> s = \"ABCD abcd AB55 55CD A55D 5555\"\n",
    ">>> re.sub(\"\\S*\\d\\S*\", \"\", s).strip()\n",
    "\n",
    "'ABCD abcd'\n",
    ">>>'''\n",
    "\n",
    "sent_1 = re.sub(\"\\S*\\d\\S*\", \" \", sent_1).strip()\n",
    "print(sent_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Data Cleaning Stage.'''\n",
    "#Data Cleaning Stage. Clean each review from the sampled Amazon Dataset\n",
    "\n",
    "''' pattern = re.compile('<.*?>') #Function to clean html tags from a sentence\n",
    "    cleaned_text = re.sub(pattern,' ',sentence)\n",
    "    return cleaned_text'''\n",
    "\n",
    "#Remove words with numbers python: https://stackoverflow.com/a/18082370/4084039\n",
    "def removeNumbers(sentence):\n",
    "    sentence = re.sub(\"\\S*\\d\\S*\", \" \", sentence).strip()\n",
    "    return (sentence)\n",
    "\n",
    "#Function to clean html tags from a sentence\n",
    "def removeHtml(sentence): \n",
    "    pattern = re.compile('<.*?>')\n",
    "    cleaned_text = re.sub(pattern,' ',sentence)\n",
    "    return cleaned_text\n",
    "\n",
    "#Remove URL from sentences.\n",
    "def removeURL(sentence):\n",
    "    text = re.sub(r\"http\\S+\", \" \", sentence)\n",
    "    sentence = re.sub(r\"www.\\S+\", \" \", text)\n",
    "    return (sentence)\n",
    "    \n",
    "#Function to keep only words containing letters A-Z and a-z. This will remove all punctuations, special characters etc. https://stackoverflow.com/a/5843547/4084039\n",
    "def removePunctuations(sentence):\n",
    "    cleaned_text  = re.sub('[^a-zA-Z]',' ',sentence)\n",
    "    return (cleaned_text)\n",
    "\n",
    "#https://stackoverflow.com/questions/37012948/regex-to-match-an-entire-word-that-contains-repeated-character\n",
    "#Remove words like 'zzzzzzzzzzzzzzzzzzzzzzz', 'testtting', 'grrrrrrreeeettttt' etc. Preserves words like 'looks', 'goods', 'soon' etc. We will remove all such words which has three consecutive repeating characters.\n",
    "def removePatterns(sentence): \n",
    "    cleaned_text  = re.sub(\"\\\\s*\\\\b(?=\\\\w*(\\\\w)\\\\1{2,})\\\\w*\\\\b\",' ',sentence)\n",
    "    return (cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stemming and stopwords removal\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "sno = SnowballStemmer(language='english')\n",
    "\n",
    "#Removing the word 'not' from stopwords\n",
    "default_stopwords = set(stopwords.words('english'))\n",
    "remove_not = set(['no', 'nor', 'not'])\n",
    "custom_stopwords = default_stopwords - remove_not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will check the distribution of stemmed word lengths across the whole review dataset to understand what is the length of the maximum number of words we will consider for the word to be relevant.\n",
    "#In other words we will keep only those words which has a length less than that of a speicific length (we will obtain this specific length from the histogram).\n",
    "from tqdm import tqdm\n",
    "total_words = []\n",
    "\n",
    "for review in tqdm(final_data['Phrase'].values):\n",
    "    filtered_sentence=[]\n",
    "    review = decontracted(review)\n",
    "    review = removeNumbers(review)\n",
    "    review = removeHtml(review)\n",
    "    review = removeURL(review)\n",
    "    review = removePunctuations(review)\n",
    "    review = removePatterns(review)\n",
    "    \n",
    "    for cleaned_words in review.split():   \n",
    "        if((cleaned_words not in custom_stopwords)):          \n",
    "            stemed_word=(sno.stem(cleaned_words.lower()))\n",
    "            total_words.append(stemed_word)\n",
    "\n",
    "total_words = list(set(total_words)) #Get list of unique words.\n",
    "\n",
    "#A list to hold the length of each words used in all the reviews used across the whole dataset.\n",
    "dist = []\n",
    "for i in tqdm(total_words):\n",
    "    length = len(i)\n",
    "    dist.append(length)\n",
    "\n",
    "# matplotlib histogram to see the distribution of the length of words\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.hist(dist, color = 'red', edgecolor = 'blue', bins =90)\n",
    "plt.title('Distribution of the length of Words across all reviews.')\n",
    "plt.xlabel('Word Lengths')\n",
    "plt.ylabel('Number of Words')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion from the above histogram: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that most stemmed words present in the reviews has lengths between 3 and 10. Words which has length greater than 13 are very very very few as compared to other words. So we will discard these words from the reviews when we process them. It means we will consider only those words whose length is greater than 2 and less than 13."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining all the above data cleaning methodologies as discussed above.\n",
    "\n",
    "#Processing review Texts\n",
    "preprocessed_reviews = [] #Store all the processed reviews\n",
    "all_positive_words=[] #Store all the relevant words from Positive reviews\n",
    "all_negative_words=[] #Store all the relevant words from Negative reviews\n",
    " \n",
    "count=0     #Iterator to iterate through the list of reviews and check if a given review belongs to the positive or negative class\n",
    "string=' '    \n",
    "stemed_word=' '\n",
    "\n",
    "for review in tqdm(final_data['Phrase'].values):\n",
    "    filtered_sentence=[]\n",
    "    review = decontracted(review)\n",
    "    review = removeNumbers(review)\n",
    "    review = removeHtml(review)\n",
    "    review = removeURL(review)\n",
    "    review = removePunctuations(review)\n",
    "    review = removePatterns(review)\n",
    "    \n",
    "    for cleaned_words in review.split():   \n",
    "        if((cleaned_words not in custom_stopwords) and (2<len(cleaned_words)<16)):\n",
    "            stemed_word=(sno.stem(cleaned_words.lower()))                                   \n",
    "            filtered_sentence.append(stemed_word)\n",
    "            if (final_data['SentimentPolarity'].values)[count] == 'Positive': \n",
    "                all_positive_words.append(stemed_word) #List of all the relevant words from Positive reviews\n",
    "            if(final_data['SentimentPolarity'].values)[count] == 'Negative':\n",
    "                all_negative_words.append(stemed_word) #List of all the relevant words from Negative reviews\n",
    "        else:\n",
    "            continue\n",
    "    review = \" \".join(filtered_sentence) #Final string of cleaned words    \n",
    "    preprocessed_reviews.append(review.strip()) #Data corpus contaning cleaned reviews from the whole dataset\n",
    "    count+=1\n",
    "    \n",
    "#Save the list of positive words and negative words\n",
    "import pickle\n",
    "with open('all_positive_words.pkl', 'wb') as file:\n",
    "    pickle.dump(all_positive_words, file)\n",
    "    \n",
    "with open('all_negative_words.pkl', 'wb') as file:\n",
    "    pickle.dump(all_negative_words, file)\n",
    "    \n",
    "#Adding a column of CleanedText to the table final which stores the data_corpus after pre-processing the reviews \n",
    "final_data['CleanedText']=preprocessed_reviews \n",
    "    \n",
    "print(\"The length of the data corpus is : {}\".format(len(preprocessed_reviews)))\n",
    "\n",
    "#Adding a column of CleanedText to the table final which stores the data_corpus after pre-processing the reviews \n",
    "final_data['CleanedText']=preprocessed_reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this code block : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. We define a function which is used to perform column standardization on any give input matrix.\n",
    "2. We define a function which is used to get the top 50 features from both the negative and the positive review classes.\n",
    "3. We define a function which is used to measure the various performance metrics for a given model. We will use accuracy as a metric to evaluate this models performance on unseen data.\n",
    "4. We define a function which is used to obtain the optima value of alpha along with the best mnodel estimator, using time series cross validation along with grid search CV.\n",
    "5. We define a function which is used to plot and visually represent the errors vs hyperparameter plot.\n",
    "6. We fit the naive base classifier to our training data and make the final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n",
    "\n",
    "def standardize(X_train_vectors, X_test_vectors):\n",
    "    '''Function used to column standardize any given matrix'''\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    scalar = StandardScaler(with_mean=False)\n",
    "    scalar.fit(X_train_vectors)\n",
    "    X_train_vectors = scalar.transform(X_train_vectors)\n",
    "    X_test_vectors = scalar.transform(X_test_vectors)\n",
    "    print(\"The shape of the X_train_vectors is : {}\".format(X_train_vectors.shape))\n",
    "    print(\"The shape of the X_test_vectors is : {}\".format(X_test_vectors.shape))\n",
    "    return (X_train_vectors, X_test_vectors)\n",
    "\n",
    "def top_features(nb_classifier, vectorizer_object):\n",
    "    '''Get top 50 features displayed from both the negative and the positive review classes.'''\n",
    "    neg_class_prob_sorted = (-nb_classifier.feature_log_prob_[0, :]).argsort()               #Note : Putting a - sign indicates the indexes will be sorted in descending order.\n",
    "    pos_class_prob_sorted = (-nb_classifier.feature_log_prob_[1, :]).argsort()\n",
    "    neg_class_features = np.take(vectorizer_object.get_feature_names(), neg_class_prob_sorted[:50])\n",
    "    pos_class_features = np.take(vectorizer_object.get_feature_names(), pos_class_prob_sorted[:50])\n",
    "    print(\"The top 50 most frequent words from the positive class are :\\n\")\n",
    "    print(pos_class_features)\n",
    "    print(\"\\nThe top 50 most frequent words from the negative class are :\\n\")\n",
    "    print(neg_class_features)\n",
    "    del(neg_class_prob_sorted, pos_class_prob_sorted, neg_class_features, pos_class_features)\n",
    "\n",
    "def performance(nb_classifier, vectorizationType, X_train, y_train, X_test, y_test, optimal_alpha, mse): #MSE : Mean Squared Loss\n",
    "    '''Function to measure the various performance metrics for a given model.'''\n",
    "    print(\"\\n'''PERFORMANCE EVALUATION'''\")\n",
    "    print(\"\\n\\nDetailed report for the {} Vectorization.\".format(vectorizationType))\n",
    "\n",
    "    #Predict the labels for the test set.\n",
    "    y_pred = nb_classifier.predict(X_test)\n",
    "    \n",
    "    #Evaluate the accuracy of the model on test set\n",
    "    test_accuracy = accuracy_score(y_test, y_pred, normalize=True) * 100\n",
    "    points = accuracy_score(y_test, y_pred, normalize=False)\n",
    "    print('\\nThe number of accurate predictions out of {} data points on unseen data is {}'.format(X_test.shape[0], points))\n",
    "    print('Accuracy of the {} model on unseen data is {} %'.format(vectorizationType, np.round(test_accuracy,2)))\n",
    "    \n",
    "    #Get the precision, recall and F1 score for this model.\n",
    "    print(\"Precision of the {} model on unseen data is {}\".format(vectorizationType, np.round(metrics.precision_score(y_test ,y_pred),4)))\n",
    "    print(\"Recall of the {} model on unseen data is {}\".format(vectorizationType, np.round(metrics.recall_score(y_test ,y_pred),4)))\n",
    "    print(\"F1 score of the {} model on unseen data is {}\".format(vectorizationType, np.round(metrics.f1_score(y_test ,y_pred),4)))\n",
    "    \n",
    "    #Classification Report\n",
    "    print ('\\nClasification report for {} model : \\n'.format(vectorizationType))\n",
    "    print(metrics.classification_report(y_test,y_pred))\n",
    "    \n",
    "    #Print the Conclusions on the trained dataset\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    p = tp+fn #p = total number of actual postives\n",
    "    n = fp+tn #p = total number of actual negatives\n",
    "    TPR = tp/p ; TNR = tn/n ; FPR = fp/n ; FNR = fn/p\n",
    "    print(\"\\nThe True Positives Rate is : {}\".format(TPR))\n",
    "    print(\"The True Negatives Rate is : {}\".format(TNR))\n",
    "    print(\"The False Positives Rate is : {}\".format(FPR))\n",
    "    print(\"The False Negatives Rate is : {}\".format(FNR))\n",
    "    \n",
    "    #Inference\n",
    "    print(\"\\nOf all the reviews that the model has predicted to be positive, {}% of them are actually positive.\".format(np.round(metrics.precision_score(y_test ,y_pred)*100,2)))\n",
    "    print(\"Of all the reviews that are actually positive, the model has predicted {}% of them to be positive.\".format(np.round(metrics.recall_score(y_test ,y_pred)*100,2)))\n",
    "      \n",
    "    #Save the below list for later use to display model information\n",
    "    info_model_NB = [vectorizationType, optimal_alpha, np.round(np.array(mse).mean(),4), np.round(1-metrics.accuracy_score(y_test, y_pred),4), np.round(metrics.f1_score(y_test ,y_pred),4), points]\n",
    "    with open('info_model_NB.txt', 'a') as filehandle:  \n",
    "        filehandle.writelines(\"%s \" % iterator for iterator in info_model_NB)\n",
    "        filehandle.writelines(\"\\n\")\n",
    "        \n",
    "    #Get the confusion matrix for the running model\n",
    "    print(\"\\nFind below the confusion matrix for {} model.\".format(vectorizationType))\n",
    "    sciplot.plot_confusion_matrix(y_test ,y_pred)\n",
    "    \n",
    "    #Free memory allocations\n",
    "    del(X_train, y_train, X_test, y_test, vectorizationType, y_pred, nb_classifier)\n",
    "       \n",
    "def get_GridSearchCV_estimator(vectorizationType, X_train, y_train, X_test, y_test):\n",
    "    '''This function will determine the best hyperparameters using TimeSeriesSplit CV and Grid Search, using 10 fold cross validation. '''\n",
    "    from sklearn.model_selection import TimeSeriesSplit\n",
    "    alphas = np.logspace(-5, 4, 100)\n",
    "    tuned_parameters = [{'alpha': alphas}]\n",
    "    n_folds = 10\n",
    "    model = MultinomialNB()\n",
    "    gsearch_cv = GridSearchCV(estimator=model, param_grid=tuned_parameters, cv=10, scoring='f1', n_jobs=6)\n",
    "    gsearch_cv.fit(X_train, y_train)\n",
    "    print(\"\\nGridSearchCV completed for {} model!\".format(vectorizationType))\n",
    "    print(\"Best estimator for {} model : \".format(vectorizationType), gsearch_cv.best_estimator_)\n",
    "    print(\"Best Score for {} model : \".format(vectorizationType), gsearch_cv.best_score_)\n",
    "    return gsearch_cv\n",
    "    \n",
    "def plot_errors(gsearch_cv):\n",
    "    '''This function is used to plot the curve for mean squared errors vs alpha values'''\n",
    "    #Get cross validation scores. Here we obtain the alpha values and their corresponding mean test scores.\n",
    "    cv_result = gsearch_cv.cv_results_         \n",
    "    mts = cv_result[\"mean_test_score\"]        #list that will hold the mean of cross validation accuracy scores for each alpha\n",
    "    alphas = cv_result[\"params\"]\n",
    "\n",
    "    alpha_values = []                         #list that will hold all the alpha values that the grid search cross validator tried.\n",
    "    for i in range(0,len(alphas)):\n",
    "        alpha_values.append(alphas[i][\"alpha\"])\n",
    "\n",
    "    #Changing accuracy to mean squared error. **error = 1 - accuracy ; error = Cross Validation Errors, accuracy = Cross Validation accuracy\n",
    "    mse = [1 - x for x in mts]\n",
    "\n",
    "    #Determining best alpha from errors. 'alpha' will be best for the lowest value for error\n",
    "    optimal_alpha = alpha_values[mse.index(min(mse))] #Laplace smoothing\n",
    "    print('The optimal value of alpha is : {}'.format(optimal_alpha))     \n",
    "\n",
    "    #Plot error vs alpha values\n",
    "    plt.figure(figsize=(35,8))\n",
    "    plt.plot(alpha_values , mse, color='green', linestyle='dashed', linewidth=2, marker='o', markerfacecolor='red', markersize=10)\n",
    "    for xy in zip(alpha_values, np.round(mse,3)):\n",
    "        plt.annotate('(%s, %s)' % xy, xy=xy, textcoords='data')\n",
    "    plt.title('Plot for Errors vs Alpha Values')\n",
    "    plt.xlabel('Values of Alpha')\n",
    "    plt.ylabel('Errors')\n",
    "    plt.show()\n",
    "    \n",
    "    return (optimal_alpha,mse)\n",
    "    \n",
    "def naive_bayes_algorithm(X_train, y_train, X_test, y_test, vectorizationType, vectorizer_object):\n",
    "    '''This function splits the dataset into training set and test sets. The test data remains untouched.\n",
    "    A time series 10 fold cross validation is performed on the train data and the value of optimal alpha is calculated. \n",
    "    The dataset is then trained with this value of optimal alpha. \n",
    "    Finally the Naive Bayes model is used to predict its accuracy on the future unseen test set.'''\n",
    "    \n",
    "    #Perform 10-fold cross validation on the train set\n",
    "    print(\"Starting Cross Validation steps...\")\n",
    "    gsearch_cv = get_GridSearchCV_estimator(vectorizationType, X_train, y_train, X_test, y_test)\n",
    "    \n",
    "    #Plot the graphical representation of the mean squared error vs the alpha values obtained during cross validation.\n",
    "    optimal_alpha, mse = plot_errors(gsearch_cv)\n",
    "\n",
    "    #Initialize the Naive Bayes constructor using alpha = optimal_alpha\n",
    "    nb_classifier = gsearch_cv.best_estimator_\n",
    "\n",
    "    #Fit the model to the train set using optimal alpha\n",
    "    nb_classifier.fit(X_train, y_train)\n",
    "    \n",
    "    #Display the top features of both the negative and positive reviews\n",
    "    top_features(nb_classifier, vectorizer_object)\n",
    "    \n",
    "    #Evaluate the model's performance\n",
    "    performance(nb_classifier, vectorizationType, X_train, y_train, X_test, y_test, optimal_alpha, mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes on the Bag of Words model created using 'CleanedText'. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A bag-of-words model, or BoW for short, is a way of extracting features from text for use in modeling, such as with machine learning algorithms. The approach is very simple and flexible, and can be used in a myriad of ways for extracting features from documents. Suppose we have N reviews in our dataset and we want to convert the words in our reviews to vectors. We can use BOW as a method to do this. What it does is that for each unique word in the data corpus, it creates a dimension. Then it counts how many number of times a word is present in a review. And then this number is placed under that word for a corresponding review. We will get a Sparse Matrix representation for all the worods inthe review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Creating the Bag of Words vector for the cleaned reviews.'''\n",
    "#Bag of Words model creation using cleaned text \n",
    "\n",
    "sampled_dataset = final_data\n",
    "\n",
    "#Split the data set into train and test sets. The test set should be unseen. Time Based Splitting Step 2.\n",
    "#The top old 80% data will get into the train set. The latest 20% data will get into the test set.\n",
    "X = sampled_dataset['CleanedText']\n",
    "y = sampled_dataset['Class_Labels']\n",
    "split = math.floor(0.8*len(X))\n",
    "X_train = X[0:split,] ; y_train = y[0:split,]\n",
    "X_test = X[split:,] ; y_test = y[split:,]\n",
    "\n",
    "#Initializing the BOW constructor\n",
    "cv_object = CountVectorizer().fit(X_train)\n",
    "\n",
    "#Creating the BOW matrix from cleaned data corpus. Only 'not' is preserved from stopwords. This is done for both train and test Vectors.\n",
    "print(\"\\nCreating the BOW vectors using the cleaned corpus\")\n",
    "X_train_vectors = cv_object.transform(X_train)\n",
    "X_test_vectors = cv_object.transform(X_test)\n",
    "\n",
    "#Colum Standardization of the Bag of Words vector created using cleaned data. This is done for both train and test Vectors.\n",
    "X_train_vectors, X_test_vectors = standardize(X_train_vectors, X_test_vectors)\n",
    "\n",
    "#Free memory allocations. \n",
    "del(sampled_dataset, X, y, X_train, X_test)\n",
    "\n",
    "#Fitting the Naive Bayes to the BOW model\n",
    "naive_bayes_algorithm(X_train_vectors, y_train, X_test_vectors, y_test, \"Bag-of-Words\", cv_object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes on the TF-IDF model created using 'CleanedText' texts. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In information retrieval, tf–idf or TFIDF, short for term frequency–inverse document frequency, is a numerical statistic that is intended to reflect how important a word is to a document in a collection or corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's assume we have data corpus D, which contains N reviews {r1,r2,r3,r4...rN}. Let's say our review r1 contains the following words {w1,w2,w3,w1,w9,w6,w7,w9,w9}."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF or Term Frequency for a word is basically the number of times a word occurs in a review divided by the total number of words present in that same review. For example, in the text corpus that we have considered in the above example, the TF for word w1 is (2/9) and for word w9 is (1/3). Intuitively, higher the occurence of a word in a text is, greater will be its TF value. TF values lies between 0 and 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IDF or Inverse Document Frequency for a word is given by the formula log(N/n), where 'N' is equal to the total number of reviews in the corpus 'D' and 'n' refers to the number of reviews in 'D' which contains that specific word. Intuitively, IDF will be higher for words which occur rarely and will be less for words which occurs more frequently. IDF values are more than 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So for each word in each review we will consider the product of (TF x IDF), and represent it in a d dimensional vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF-IDF basically doesn't consider the semantic meaning of words. But what is does is that it gives more importance to words which occurs less frequently in the whole data corpus and also gives much importance to the most frequent words that occurs in each review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''TF-IDF model creation using text reviews. HTML tags and punctuations are removed. All stopwords are preserved.'''\n",
    "\n",
    "\n",
    "sampled_dataset = final_data\n",
    "\n",
    "#Split the data set into train and test sets. The test set should be unseen. Time Based Splitting Step 2.\n",
    "#The top old 80% data will get into the train set. The latest 20% data will get into the test set.\n",
    "X = sampled_dataset['CleanedText']\n",
    "y = sampled_dataset['Class_Labels']\n",
    "split = math.floor(0.8*len(X))\n",
    "X_train = X[0:split,] ; y_train = y[0:split,]\n",
    "X_test = X[split:,] ; y_test = y[split:,]\n",
    "\n",
    "#Initializing the TF-IDF contructor\n",
    "tf_idf_object = TfidfVectorizer(ngram_range=(1,1)).fit(X_train)\n",
    "\n",
    "#Creating the BOW matrix from cleaned data corpus. Only 'not' is preserved from stopwords. This is done for both train and test Vectors.\n",
    "print(\"\\nCreating the TFIDF vectors using the cleaned corpus\")\n",
    "X_train_vectors = tf_idf_object.transform(X_train)\n",
    "X_test_vectors = tf_idf_object.transform(X_test)\n",
    "\n",
    "#Colum Standardization of the TF-IDF vector created using cleaned data. This is done for both train and test Vectors.\n",
    "X_train_vectors, X_test_vectors = standardize(X_train_vectors, X_test_vectors)\n",
    "\n",
    "#Free memory allocations.\n",
    "del(sampled_dataset, X, y)\n",
    "\n",
    "#Fitting the Naive Bayes to the BOW model\n",
    "naive_bayes_algorithm(X_train_vectors, y_train, X_test_vectors, y_test, \"TF-IDF\", tf_idf_object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the below comparison chart we can see get an idea aboout how the different vectorizers perform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compare performance and display it on a pretty table.\n",
    "from prettytable import PrettyTable\n",
    "table = PrettyTable()\n",
    "table.field_names = [\"Model\", \" Hyper-Parameter Value (alpha=)\", \"Train Error\", \"Test Error\", \"F1-Score\", \"No. Of accurate predictions\"]\n",
    "\n",
    "print(\"Please find below the important metrics for all the models below.\\n\")\n",
    "file = open('info_model_NB.txt', 'r')\n",
    "file.seek(0)\n",
    "for line in file:\n",
    "    table.add_row(line.split())\n",
    "print(table[7:9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
